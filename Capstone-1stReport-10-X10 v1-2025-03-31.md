<!-- Template for PROJECT REPORT of CapstoneDesign 2025-2H, initially written by khyoo -->
<!-- 본 파일은 2025년도 컴공 졸업프로젝트의 <1차보고서> 작성을 위한 기본 양식입니다. -->
<!-- 아래에 "*"..."*" 표시는 italic체로 출력하기 위해서 사용한 것입니다. -->
<!-- "내용"에 해당하는 부분을 지우고, 여러분 과제의 내용을 작성해 주세요. -->

# Team-Info
| (1) 과제명 | 음성 분석 기반 졸음 감지 및 개인화된 음성 대화를 통한 졸음 운전 예방 서비스
|:---  |---  |
| (2) 팀 번호 / 팀 이름 | 10 - X10 |
| (3) 팀 구성원 | **곽선호 (2076017)**<br> - 리더, Backend Developer / 스토리지 설계 및 구현 (ERD 작성, RDS), API 설계, 서버 로직 코드 구현, 무중단 서버 구축 및 배포 <br><br> **강민정(2229001)** <br> - 팀원, AI Developer / 머신러닝 모델 개발(졸린 음성 감지, 하품 음성 감지, 대화 내용 요약), AI 모델 서빙 <br><br> **안수이 (2128014)** <br> - 팀원, Frontend Developer / UI 디자인 및 설계, 안드로이드 앱의 화면 구성과 디자인 요소 기획, API 요청 및 응답 관리, 비동기 처리 및 상태 관리, 서비스 최종 점검			 |
| (4) 팀 지도교수 | 오세은 교수님 |
| (5) 과제 분류 | 산학과제 |
| (6) 과제 키워드 | 음성분석, 맞춤형 챗봇, 졸음운전|
| (7) 과제 내용 요약 | 저희는 음성 분석을 기반으로 운전자의 졸음을 감지하고 생성형 AI 기반의 개인 맞춤형 음성 대화 기능을 제공하는 졸음 운전 사고 예방 서비스를 만들고자 합니다. |

<br>

# Project-Summary
| 항목 | 내용 |
|:---  |---  |
|(1) 문제 정의 |<br> 1인 운전자의 졸음운전 사고를 예방하기 위한 음성 감지 및 대화 시스템을 개발하고자 한다. 졸음운전으로 인해 하루 평균 5.9건의 사고가 발생하며, 이는 음주운전 사고보다 약 2배 높은 치사율을 보인다. 특히, 졸음운전 사고의 82.5%는 운전자가 혼자일 때 발생하는 것으로 보고되었다. 그러나 현재 졸음운전 방지 서비스를 사용해본 사람은 극히 적으며(자체 설문조사 결과, 1.5%), 이에 대한 필요성을 느끼고 있다.<br><br>**Target Customer 및 Pain points**<br>본 서비스의 주요 대상 고객은 다음와 같다.<br>1. 이른 아침 및 심야 운전을 자주 하거나, 피로할 때 깨워줄 동승자가 없어 불안한 1인 운전자<br>2. 기존의 카메라 기반 졸음 감지 시스템 이용에 불편함을 느끼는 사용자<br>3. 혼자 운전할 때 지루함과 외로움을 느끼는 1인 운전자<br><br>다음과 같은 문제들을 해결하여 보다 안전하고 즐거운 운전 환경을 조성하는 것을 목표로 한다.<br>1. 졸음운전 사고 예방: 새벽이나 야간 주행 시 졸음운전 위험이 높아 효과적인 방지책이 필요하다.<br>2. 접근성이 높고 편리한 졸음 감지 시스템 제공: 적외선 카메라가 없는 차량에서는 야간 인식이 어렵고, 운전 중 카메라를 별도로 거치하는 것이 번거로운 경우가 많다.<br> |
| (2) 기존연구와의 비교 |<br>1. **기존 졸음 감지 시스템**<br>[ 카메라 및 센서 기반 감지 ]<br>- 장점: 운전자의 신체적 변화(운전자의 눈 깜빡임, 머리 기울기 등)를 직접 감지 가능, 졸음 감지 시 알림<br>- 단점: 하드웨어(센서, 카메라 장비) 설치 필요, 접근성 및 비용 부담 증가, 야간 촬영 시 적외선 카메라 필요 및 인식률 하락, 긴 촬영으로 인한 부담감<br><br>**2. 본 과제의 장점 및 차별성**<br>[ 비접촉 방식의 졸음 감지 ]<br>- 기존의 센서 및 카메라 기반 방식과 달리 **추가 장비 없이 음성만으로 감지** 가능<br>- 운전자에게 부담을 주지 않으며, 장비 설치가 필요 없어 접근성이 높고 편리함<br><br>[ 실시간 개인화된 대화형 AI ]<br>- 기존의 단순한 경고 방식이 아닌, **운전자의 상태와 관심사에 맞춘 맞춤형 대화 제공**<br>- 1인 운전자의 경우 혼자 운전할 때의 지루함과 외로움을 줄여주고, 집중력을 유지하는 데 도움을 줌<br>- 졸음 상태를 감지하면 AI가 자연스러운 대화를 유도하여 졸음 완화<br><br>[ 음성 분석을 통한 피로도 감지 ]<br>- **음성 톤, 피치, 발화 속도를 실시간 분석**하여 졸음 징후를 파악하고 즉각적인 대응 가능<br><br>[ 다양한 졸음 방지 기능 통합 ]<br>- 단순한 경고가 아닌 **스트레칭 안내, 대화 시스템 등 다양한 방식으로 졸음 예방**<br>- 사용자가 원하는 기능을 선택하여 활용할 수 있어 맞춤형 솔루션 제공<br>|
| (3) 제안 내용 | <br>최근 연구에 따르면 디지털 어시스턴트(음성 비서)와의 대화가 운전자의 피로도를 줄이고 졸음을 예방하는 데 도움이 되는 것으로 나타났다. 특히 단순한 오디오 재생보다 운전자와 상호작용하는 대화형 시스템이 더 효과적이었다. 또한 대화의 방식과 내용이 적절하다면, 운전 중 대화가 졸음운전을 줄이는 데 도움이 될 가능성이 높으며 운전 반응 속도에는 악영향을 미치지 않는다는 점을 확인하였다. 이를 바탕으로 본 프로젝트에서는 운전 중 운전자를 방해하지 않을 정도의 적절한 대화를 통해 졸음운전을 방지하는 해결책을 제안한다.<br><br>** 참고 논문<br>- Large, David R., et al. "Driven to discussion: engaging drivers in conversation with a digital assistant as a countermeasure to passive task‐related fatigue." IET Intelligent Transport Systems 12.6)<br>- akayama, Leila, and Clifford Nass. "Assessing the effectiveness of interactive media in improving drowsy driver safety." <br><br>해결책<br>1. **음성 분석 기반 졸음 감지 시스템**<br>- 운전 중 운전자의 음성을 실시간으로 분석하여 졸음 상태를 감지한다. 음성의 특징과 하품 여부, 대화 내용 등을 종합적으로 분석하여 졸음 징후를 파악하고, 이를 바탕으로 즉각적인 경고를 제공한다.<br>2. **실시간 맞춤형 대화 시스템**<br> - AI가 자연스럽고 개인화된 대화를 유도하여 운전자의 졸음을 완화시키고 집중력을 회복시킨다. 대화 내용은 운전자의 관심사와 이전 대화 내용에 맞춰 유동적으로 변화한다. 간단한 질문을 던지거나 운전자의 기분을 체크하는 방식으로 대화를 유도한다.<br><br>이와 같은 솔루션을 통해 본 시스템은 기존의 졸음 방지 시스템과 차별화되는 장점들을 제공하며, 운전자가 보다 안전하고 편리한 운전 환경을 경험할 수 있도록 한다.<br>|
| (4) 기대효과 및 의의 |<br> **1. 졸음 운전 사고 감소**<br>개인화된 음성 대화와 졸음 감지 기능을 통해 졸음 운전을 예방함으로써 야간 운전이나 장거리 운전 중 발생할 수 있는 교통사고를 감소시키는 데 기여할 수 있다. 특히 혼자 운전하는 운전자에게 유용한 솔루션이 되어, 교통 안전이 향상될 것으로 기대된다.<br><br> **2. 졸음 감지 및 예방 기술의 상용화 가능성**<br>성공적인 졸음 예방 기술 구축을 통해, 졸음 감지 및 예방 시스템의 상용화 가능성이 높아진다. 차량이나 지도 맵에 추가적인 기능으로 상용화하면 사용자들에게 더 편리한 서비스를 제공할 수 있어 다양한 시장에서 활용될 수 있는 기술로 자리 잡을 것이다.<br>|
| (5) 주요 기능 리스트 | <br> **1. 졸음 감지**<br>1-1. 하품: 대화 중 운전자가 하품을 할 경우, 오디오 이벤트 검출 기술을 통해 하품 소리를 실시간으로 감지한다.<br>1-2. 졸린 음색: 운전자의 대화 음성에서 졸린 음색을 감지하기 위해 오디오 특성을 추출하고 분석하여 피로도를 판단한다.<br>1-3. 대화 내용: 텍스트 변환(STT)을 이용하여 사용자의 대화 내용을 텍스트로 변환한 후, 미리 설정된 졸음 관련 키워드(예: ‘졸려’, ‘피곤해’)가 발화될 경우 이를 졸음 신호로 인식한다.<br><br>**2. 개인 맞춤형 음성 챗봇**<br>2-1. 실시간 개인화 대화: 회원 가입 시 수집된 사용자의 정보 및 관심사와 대화 중 축적된 데이터를 바탕으로 개인의 취향과 상황에 맞는 대화를 실시간으로 제공한다.<br>2-2. 프롬프트 엔지니어링: 사용자 정보를 전달하는 GPT-4o의 프롬프트 엔지니어링을 통해 실제 사람과 대화하는 듯한 자연스럽고 몰입감 있는 대화 경험을 제공한다.<br><br>**3. 졸음 감지 후 액션**<br>3-1. 경고 알림: 졸음 감지를 통해 졸음 상태가 감지되면, 경고 알림이 큰 소리로 운전자에게 전달되어 즉시 주의를 환기한다.<br>3-2. 졸음 완화 음성 안내: 졸음 상태가 감지된 후, 챗봇이 자연스럽고 친근한 대화를 이어가거나, 간단한 스트레칭 동작을 음성으로 안내하여 졸음을 완화한다.<br><br>**4. 대화 종료 후 데이터 저장**<br>4-1. 대화 요약: 전체 대화 내역을 분석하여 핵심적인 대화 내용을 간추린 한 줄 요약을 생성한다. 이 요약은 사용자의 ‘대화 내역 화면’에 제공된다.<br>4-2. 키워드 추출: 전체 대화 내역 중 사용자 정보와 관련된 중요한 키워드를 추출하여 DB에 저장된다. 이 정보는 같은 사용자가 다시 서비스를 이용할 때 대화 생성에 참고자료로 사용된다.|
<br>
 
# Project-Design & Implementation
| 항목 | 내용 |
|:---  |---  |
| (1) 요구사항 정의 |<br> **1. 기능별 상세 요구사항(또는 유스케이스)**<br>![image](https://github.com/user-attachments/assets/6177c265-7e05-4df4-81cf-eb6533b9d2b5)![image](https://github.com/user-attachments/assets/83112a97-53b3-4cb7-85ba-dc8c6cf512a0) <br><br><br> **2. 설계 모델(클래스 다이어그램, 클래스 및 모듈 명세서)**<br>![image](https://github.com/user-attachments/assets/a6402727-f984-4cea-8ead-bed3811bc7ac)<br><br><br> **3. UI 분석/설계 모델** <br>* 주요 화면 설계<br><br>![image](https://github.com/user-attachments/assets/4e02cc65-2060-4741-92b5-552f46416069)<br><br><br> **4. E-R 다이어그램/DB 설계 모델(테이블 구조)**<br><br>![image](https://github.com/user-attachments/assets/dfed55d1-8702-4f7b-891e-ed71b2fe9a13)|
| (2) 전체 시스템 구성 |<br>![image](https://github.com/user-attachments/assets/6185d9a3-b6c5-41ed-9a64-b66228d04d1c)<br><br>**1) Front-End**<br>- React Native로 안드로이드 어플을 제작하고 언어는 typescript를 사용하며 axios를 사용하여 백엔드와 api 통신을 한다.<br>- 카카오 API를 사용해 로그인을 구현하고 유튜브 API를 사용하여 스트레칭 영상 리스트를 사용자에게 제공한다. OpenAI GPT API를 사용하여 음성 챗봇을 구현하고 이 과정에서 Whisper API를 사용하여 tts 기능을 사용한다.<br><br>**(2) Back-End**<br>- SpringBoot로 메인 서버(RESTful API)를 구현하고, 언어는 java를 사용하며 IDE는 IntelliJ를 사용한다.<br>- AWS RDS로 DB를 구축하고, EC2와 Github Actions로 서버를 배포하여 CI/CD를 자동화한다. 카카오 API를 사용하여 카카오ID 값을 받아와, 앱 내에서 인증 및 인가에 사용하는 JWT 토큰 인증 방식을 구현한다.<br>- 메인 서버와 AI 서버를 각각 두었기 때문에, Docker를 사용하여 각각의 서버를 컨테이너화하고, 각 서버는 서로 다른 포트에서 실행되게 설정한다.<br><br>**(3) AI**<br>- AI 시스템은 Python 언어를 사용하고 PyTorch를 기반으로 개발한다. 실시간 음성 데이터를 처리하여 졸음 상태를 감지하고 대화를 요약하는 기능을 수행한다.<br>- 프론트엔드에서 수집한 운전자의 실시간 음성을 두 가지 졸음 감지 모델(하품 감지 및 음색 기반 졸음 감지)을 통해 분석한 후, 추론 결과를 반환한다. 대화 종료 시 음성 데이터의 텍스트 변환 결과를 요약하여 주요 내용을 추출하고, 이를 백엔드로 전달하여 데이터베이스에 저장한다.<br>- AI 모델의 서빙은 FastAPI를 활용하여 구축된 AI 서버에서 수행되며, 실시간 추론과 데이터 처리가 원활하게 이루어지도록 설계하였다.|
| (3) 주요엔진 및 기능 설계 | <br>**주요 엔진**<br>1. 사용자 음성을 인식해 텍스트로 변환하는 모듈: **Whisper-stt API**<br>2. 챗봇 모듈: **Gpt-4o**<br>3. 음성 챗봇 구현 & 프롬프트 적용 & 졸음 키워드 매칭: **React-Native**<br>4. 자체 개발 모델 구현: **Pytorch**<br>5. 하품 소리 인식의 기반이 되는 사전학습 모델: **YAMNet**<br>6. 졸린 음색 감지를 위한 음향 특징 추출: **Wav2Vec 2.0, librosa**<br><br>**1) 프롬프트 엔지니어링으로 구현한 개인 맞춤형 음성 챗봇**<br>우리 프로젝트는 초기에 입력한 사용자의 정보에 따라 실제 친구처럼 맞춤형 대화를 하는 기능을 가지고 있어 프롬프트 엔지니어링으로 이를 해결했다. <br><br>**2) 사용자의 졸음 상태 감지(텍스트 기반)**<br>우리 프로젝트는 사용자의 졸음 상태를 텍스트와 음성 기반으로 감지하는 기능이 있는데 그 중 텍스트 기반 감지를 해결하기 위해, 즉 사용자의 음성을 Whisper API 모듈로 텍스트로 변환한 후 졸리다는 키워드를 감지하면 졸음을 예방하기 위한 해결책을 준다.<br><br>**시나리오**<br>1. 사용자가 “졸려”라고 말하는 경우 → “졸려? 스트레칭 알려줄까?” 라고 gpt가 대답.<br>2. 사용자가 “종료”가 들어가는 말을 하는 경우 → “대화 종료할게. 안전 운전해!” 라고 gpt가 대답.<br><br>**3) 음향 이벤트 감지 사전학습 모델(YAMNet) 기반 하품 소리 감지 모델**   <br>우리 프로젝트는 운전자가 집중력이 떨어질 때를 인지하고, 먼저 대화를 시작하거나 적절한 졸음 감지 액션을 취하는 것이 목표이다. 따라서 하품을 하는 것을 졸음의 신호라고 보고, 이를 감지하는 모델을 구현한다.<br>AI-Hub의 ‘자연 및 인공적 발생 非언어적 소리 데이터’에서 ‘하품’ 레이블이 지정된 오디오 데이터를 사용하고, 모든 오디오 데이터는 16kHz로 리샘플링한다. YAMNet을 활용한 전이 학습 방식으로 추출된 오디오 특성을 기반으로 분류 신경망을 구축한다. 실시간 환경에서 추론 속도를 최적화하는 작업을 진행한다.<br><br>4) **음향 특징 추출(Audio Feature Extraction) 기반 졸린 음색 감지(감정 분석) 모델**   <br>졸음의 신호를 감지하는 또 다른 방법으로 ‘졸린’ 음색을 감지하는 음성 감정 분석 모델을 구현한다.<br>EmoV-DB 데이터셋의 ‘Sleepy’ 레이블이 지정된 오디오 데이터를 사용하고, 모든 오디오 데이터는 16kHz로 리샘플링한다. wav2vec 2.0을 사용하여 fine-tuning하는 방식과 MFCC를 입력으로 받아 분류하는 신경망 모델을 구현한다. 추후 실시간 환경에서 추론 속도를 최적화하는 작업을 진행한다.|
| (4) 주요 기능의 구현 |<br>1. **하품 감지 모델**<br>기존의 YAMNet 활용 모델은 특정 유형의 데이터에 과적합되는 경향을 보여 새로운 모델 구조 도입과 음성 증강을 시도하고 있다. CRNN(Convolutional Recurrent Neural Network)와 AST(Audio Spectrogram Transformer) 등의 모델을 비교 실험하고 있으며, 음성 증강 기법으로는 잡음 추가, 음높이 변화 등을 적용하여 데이터 다양성을 확보하고자 한다.<br><br>![image](https://github.com/user-attachments/assets/39abdf43-82f8-4492-8e90-ef7a890a72db)<br>![image](https://github.com/user-attachments/assets/42f32ed4-02b7-4423-b2d6-96d6474d502a)<br><br><br><br>2. **졸린 음색 감지 모델**<br>기존의 MFCC 및 wav2vec 2.0을 활용한 모델은 성능 한계가 있어 새로운 모델 구조를 검토하고 있다. 현재 실험 중인 모델은 VGGish, HuBERT, TitaNet 등이다.<br>![image](https://github.com/user-attachments/assets/6652636f-ed87-449e-bcac-f5e0bf64e5b3)<br>![image](https://github.com/user-attachments/assets/e3653737-0917-46a1-af1a-81536226f5c3)<br><br><br><br>3. **프롬프트 엔지니어링으로 구현한 개인 맞춤형 음성 챗봇**<br>- 우리 프로젝트는 초기에 입력한 사용자의 정보에 따라 실제 친구처럼 맞춤형 대화를 하는 기능을 가지고 있어 프롬프트 엔지니어링으로 이를 해결했다. 여러 번 시행착오를 겪으며 프롬프트 내용을 수정하였다.<br><br> - 시나리오<br>대화 시작 버튼 클릭 <br> → gpt가 사용자에게 말을 걸어 음성 대화를 시작한다.<br> → 사용자 맞춤 정보를 기반으로 대화한다.<br><br>![image](https://github.com/user-attachments/assets/9dc482e2-df07-4845-b03d-fc5bb4a386fc)<br>![image](https://github.com/user-attachments/assets/cee0e6c8-f426-4370-ba12-46eea2f80c2c)<br>![image](https://github.com/user-attachments/assets/d16db0e0-db2b-43d1-bc54-c6e825093d69)|
| (5) 기타 | **2024 SW 중심대학 생성형 AI 활용경험 공모전 우수상 수상** |

<br>
